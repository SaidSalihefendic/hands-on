{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Machine Learning Landscape\n",
    "\n",
    "In this chapter, we will discuss about the fundamental concepts that, like the author said, every data scientist should know by heart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Machine Learning?\n",
    "\n",
    "*training set*, *training instance*, *training data*, *accuracy*, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Use Machine Learning?\n",
    "\n",
    "Comparrisons with traditional techniques and machine learning techniques\n",
    "Examples: spam filter, speech recognition\n",
    "Data mining\n",
    "\n",
    "To summarize:\n",
    "* Problems for which existing solutions require a lot of hand-tuning or long lists of rukes: one machine learning algorithm can often simplify code and perform better\n",
    "* Complex problems for which there is no good solution at all using a traditional approach: the best Machine Learning technique can find a solution.\n",
    "* Fluctuating environments: a Machine Learning system can adapt to new data.\n",
    "* Getting insights about complex problems and large amounts of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Machine Learning Systems\n",
    "\n",
    "Supervised, unsupervised, semisupervised, reinforcement learning\n",
    "Online versus batch learning\n",
    "instance-based learning, model-based learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Learning\n",
    "\n",
    "Learning on labeled data\n",
    "\n",
    "labels, classification, class, target, features, predictors, regression\n",
    "attribute, feature\n",
    "\n",
    "Most important supervised learning algorithms:\n",
    "* k-Nearest neighbor\n",
    "* Linear regression\n",
    "* Logistic regression\n",
    "* Support Vector Machines (SVMs)\n",
    "* Decision trees and Random forests\n",
    "* Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised Learning\n",
    "\n",
    "Learning on unlabeled data\n",
    "\n",
    "Most important unsupervised learning algorithms:\n",
    "\n",
    "- Clustering\n",
    "    - k-means\n",
    "    - Hierarchical CLuster Analysis (HCA)\n",
    "    - Expectation Maximization\n",
    "- Visualization and dimensionality reduction\n",
    "    - Principal Component Analysis (PCA)\n",
    "    - Kernel PCA\n",
    "    - Locally-Linear Embedding (LLE)\n",
    "    - t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "- Association rule learning\n",
    "    - Apriori\n",
    "    - Eclat\n",
    "\n",
    "Examples: Blog visitors, data organization and representation, dimensionality reduction (feature extraction), anomaly detection, association rule learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semisupervised learning\n",
    "\n",
    "Learning on partially labeled data\n",
    "\n",
    "Example: photo-hosting services, deep belief networks (DBNs, restricted Boltzmann machines RBMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinforcement learning\n",
    "\n",
    "Learning the system's policy\n",
    "\n",
    "agent, rewards, policy\n",
    "\n",
    "Examples: Robots learning how to walk, AlphaGo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch learning\n",
    "\n",
    "System incapable of learning incrementally (offline learning)\n",
    "Requires a lot of computing resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online learning\n",
    "\n",
    "Sysstem trains incrementally by feeding it data instances sequentially\n",
    "\n",
    "Mini-batches, out-of-core learning, incremental learning\n",
    "Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instance-based learning\n",
    "\n",
    "Simply to learn by heart\n",
    "\n",
    "Measure of similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-based learning\n",
    "\n",
    "Building a model of the given examples, then use the model to make predictions\n",
    "\n",
    "Model selection, example GDP-Life satisfaction correlation\n",
    "Utility function (fitness function), cost function\n",
    "Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "To summarize:\n",
    "* You studied the data\n",
    "* You selected a model\n",
    "* You trained it on the training data\n",
    "* Finally, you applied the model to make predictions on new cases (inference), hoping that this model will generalize well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Challenges of Machine Learning\n",
    "\n",
    "bad algorithm, bad data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insufficient Quantity of Training Data\n",
    "\n",
    "Most problems require lots of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nonrepresentative Training Data\n",
    "\n",
    "sampling noise, sampling bias, nonresponse bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poor-Quality Data\n",
    "\n",
    "outliers, errors, noise, missing features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Irrelevant Features\n",
    "\n",
    "feature engineering:\n",
    "- feature selection\n",
    "- feature extraction\n",
    "- creating new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting the Training Data\n",
    "\n",
    "Fits the training data, poor generalization\n",
    "Subtle patterns\n",
    "Possible solutions: simplify model, gather more training data, reduce noise in training data\n",
    "Regularization (degrees of freedom)\n",
    "Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Underfitting the Training Data\n",
    "\n",
    "Opposite of Overfitting\n",
    "Possible solutions: More powerful model with more parameters, better features, reducing the constraints on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Validating\n",
    "\n",
    "Training set, test set\n",
    "Generalization error (out-of-sample error)\n",
    "Validation set\n",
    "Cross-validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Deep Learning)",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
