{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Machine Learning Landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How would you define Machine Learning?\n",
    "\n",
    "Machine learning is the technique used to make machines get better at some task by learning from data instead of having to explicitly code rules. The Machine Learning algorithms mostly automate various tasks like image classification, speech recognition, translation and so on in order to make things easier for us humans to be better and more productive in work environments. Of course, there are also applications of Machine Learning in various research and predictions that can be crucial for making important decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Can you name four types of problems where it shines?\n",
    "\n",
    "They shine in the problems of classification, regression, speech recognition, structuring and visualizing data, image processing and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What is a labeled training set?\n",
    "\n",
    "The training set is a collection of data with attributes (also called features) that are used to feed a machine learning algorithm. The training set can be labeled or unlabeled, which depends on the task that we try to accomplish. The labeled training set is a training set that, alongside its features, contains the labels that we are trying to predict. For example, a collection of images of dogs, cats and frogs are a labeled training set for classifying images whether the image is of a cat, a dog or a frog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What are the two most common supervised tasks?\n",
    "\n",
    "The most common supervised tasks are classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Can you name four common unsupervised tasks?\n",
    "\n",
    "The common unsupervised tasks are clustering, visualizing, dimensionality reduction, anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. What type of Machine Learning algorithm would you use to allow a robot to walk in various unknown terrains?\n",
    "\n",
    "I would definitely use the Reinforcement Learning algorithms, since for walking, it requires to learn on fly based on punishments and rewards system. For this case, reinforcement learning shines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What type of algorithm would you use to segment your customers into multiple groups?\n",
    "\n",
    "I'd use the unsupervised learning algorithm that solves clustering problems, like the k-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Would you frame the problem of spam detection as a supervised learning problem or an unsupervised learning problem?\n",
    "\n",
    "I would frame this problem as a supervised learning problem because it must seek the patterns that are similar in spam emails with the emails that are flagged as spam by the users. Since the problem heavily relies on the user's feedback, this is the supervision it has for the spam emails. I think it is kinda awkward to frame this problem as unsupervised since it doesn't guarantee that the emails will split nicely into two clusters, one for not spam and one for spam emails and for every new instance, we don't know whether we will correctly put the instance into either cluster. So, in order to achieve a much better accuracy, supervised learning is the way to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What is an online learning system?\n",
    "\n",
    "An online learning system is a system that enables a machine learning algorithm to learn incrementally. In my honest opinion, I think it would be much easier to think of this system as incremental system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. What is out-of-core learning?\n",
    "\n",
    "when we have a dataset so large, it cannot fit in one's machine main memory, it suggests that we need to load part of data, run a training step on that data, and repeat the process until it has run on all of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. What type of learning algorithm relies on a similarity measure to make predictions?\n",
    "\n",
    "The instance-based learning relies on similarity measure, because the system learns the examples by heart and then it generalizes to new cases using the similarity measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. What is the difference between a model parameter and a learning algorithm's hyperparameter?\n",
    "\n",
    "The model parameter is a paramater that represents the impact a feature has in the given instance's predicton and the model parameter is learned during the learning step, while the hyperparameter is a parameter of a learning algorithm (the constant) that we define and it means how much the regularization will be applied during the learning step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. What do model-based learning algorithms search for? What is the most common stategy they use to succeed? How do they make predictions?\n",
    "\n",
    "The model-based learning algorithms search for the model of the data and use that same model for predictions. The most common stategy they use to succeed are the performance measure using the fitness function (how good the model is) or the cost (loss) function (how bad the model is)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Can you name four of the main challenges in Machine Learning?\n",
    "\n",
    "The main challenges the Machine Learning faces are poor-quality data, overfitting and underfitting, insufficient quantity of the training data, nonrepresentative training data, irrelevant features and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. If your model performs great on the training data but generalizes poorly to new instances, what is happening? Can you name three possible solutions?\n",
    "\n",
    "This process is called overfitting, because we have a model that detected subtle patterns that prevents the model's generalization. The possible solutions would be more training data, since we could face the overfitting possibly because we have the insufficient quantity for decent generalization; we could also try the different approach like reducing the noise in the training data, since we can have data errors, a lot of outliers and so on; and another approach would be to simplify the model by selecting one with fewer parameters, possibly we have overcomplicated our model, like trying to kill a fly with the gun. We could also reduce the number of features we are giving in the training set and we could also constrain a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. What is a test set and why would you want to use it?\n",
    "\n",
    "The test set is a portion of the dataset that we have split into two parts: one part training set and other part test set. I would use the test set to test the model on the instances that has never seen during the training step in order to calculate the generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. What is the purpose of a validation set?\n",
    "\n",
    "The problem with the test set can occur when we measure generalization error multiple times on the test set and adapted the model and hyperparameters to produce the best model for that test set. It means that the model is unlikely to perform as well on new data. The solution to this problem is to have a second holdout set called the validation set. It is used to select the model and hyperparameters that perform best on the validation set, and when we're satisfied with our results we run a single final test against the test set to get an estimate of the generalization error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. What can go wrong if you tune hyperparameters using the test set?\n",
    "\n",
    "As said before, when we use the same test set as a supervision for the generalization error and it is used to tune the hyperparameters, the resulting model will be best produced for that particular test set, since we used it as a guidance for best generalization, which will not necessarily perform the best on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19. What is cross-validation and why would you prefer it to a validation set?\n",
    "\n",
    "To avoid wasting too much tranining data in validation sets, a common technique is to use cross-validation. The training set is split into complementary subsets and each model is trained against a different combination of these subsets and validated against the remaining parts.Once the model type and hyperparameters have been selected, a final model is trained using these hyperparameters on the full training set and the generalization error is measured on the test set. I like the fact that we use this technique in order to avoid a task of tuning the hyperparameter and finding the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Deep Learning)",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
